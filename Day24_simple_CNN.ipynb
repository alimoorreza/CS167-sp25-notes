{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alimoorreza/CS167-sp25-notes/blob/main/Day24_simple_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHJrUI0I4uVJ"
      },
      "source": [
        "# CS167: Day24\n",
        "## Deep Learning and Convolutional Neural Network (CNN)\n",
        "\n",
        "#### CS167: Machine Learning, Spring 2025\n",
        "\n",
        "\n",
        "ðŸ“œ [Syllabus](https://analytics.drake.edu/~reza/teaching/cs167_sp25/cs167_syllabus_sp25.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XC7VEFe4uVh"
      },
      "source": [
        "## Introduction to PyTorch\n",
        "\n",
        "We can use PyTorch Framework to build and train MLPs and other neural networks such as CNN, RNN, LSTM, Transformers. Let's learn the basics of PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch library\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "LwgBlHEvJDEJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Convolution and Pooling Layers using PyTorch"
      ],
      "metadata": {
        "id": "8JllItQfeVFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's build a 2D convolution layer**\n",
        "- [nn.Conv2d()](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
        "  - applies a 2D convolution over an input volume of $(C_{in}â€‹,H_{in},W_{in})$ and produces an output volume of $(C_{out}â€‹,H_{out},W_{out})$   between two adjacent layers.\n",
        "  - to create this, you need to provide the followings:\n",
        "    - __channel_dimension_of_input_layer__ i.e., $C_{in}$\n",
        "    - __channel_dimension_of_output_layer__ i.e., $C_{out}$\n",
        "    - __filter_size__ i.e., $F$\n",
        "\n",
        "  - the other two optional parameters are __stride__: $S=1$ and __padding__: $P=0$, with default values as shown. As discussed in class, PyTorch will calculate internally the sizes of output volume $H_{out}$ and $W_{out}$ from the above mentioned parameter values\n",
        "\n",
        "\n",
        "> For example, let's create a 2D convolution layer by specify the following:\n",
        ">> input volume channels size is 1\n",
        "\n",
        ">> output volume channel size is 32\n",
        "\n",
        ">> each filter has a size of (3x3)\n",
        "\n",
        ">> default stride size is 1\n",
        "\n",
        ">> default padding size is 0"
      ],
      "metadata": {
        "id": "K6snyzopmxi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construction of a 2D convolutional layer (useful for feature map learning from the grid layouts of an image)\n",
        "input_volume_channel_first  = 8\n",
        "output_volume_channel_first = 8\n",
        "filter_size                 = 3\n",
        "\n",
        "\n",
        "first_conv_2d               = nn.Conv2d(input_volume_channel_first, output_volume_channel_first, filter_size)  # 2D convolutional transformation module :input_volume_channel=1, output_volume_channel=32, filter_size= (3x3)\n",
        "#relu_activation_1st         = nn.ReLU()\n",
        "first_conv_2d               = nn.Conv2d(8, 8, 3)  # 2D convolutional transformation module :input_volume_channel=1, output_volume_channel=32, filter_size= (3x3)\n",
        "\n"
      ],
      "metadata": {
        "id": "WovTledem6Lw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Inspecting the weights of a 2D convolution layer**"
      ],
      "metadata": {
        "id": "J2Vd7i1cOUQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the weights of the convolution filters\n",
        "print(f'Weights: \\n{first_conv_2d.weight.data.shape}')\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "t_v_9SaTOY7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ef665e-f4dc-4aa3-98b7-f4d1ced15aca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: \n",
            "torch.Size([8, 8, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first filter\n",
        "print(f'Size of first filter: \\n{first_conv_2d.weight.data[0].shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfSVlVaSwvpu",
        "outputId": "46590a62-a5a2-4313-d9b4-a0d81a773ce4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of first filter: \n",
            "torch.Size([8, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first filter\n",
        "print(f'Weights of first filter: \\n{first_conv_2d.weight.data[0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCiYDJ0_w6zP",
        "outputId": "03794d08-2ca1-4d00-f110-dab208abe51f",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights of first filter: \n",
            "tensor([[[ 0.0857, -0.1086, -0.0108],\n",
            "         [ 0.0715,  0.0448, -0.0716],\n",
            "         [ 0.1054,  0.0358,  0.0970]],\n",
            "\n",
            "        [[ 0.0556,  0.0968,  0.0547],\n",
            "         [ 0.1030,  0.0508,  0.0030],\n",
            "         [-0.0906, -0.1054, -0.0420]],\n",
            "\n",
            "        [[-0.0897,  0.0460,  0.0294],\n",
            "         [-0.0624, -0.0090,  0.0548],\n",
            "         [ 0.0541, -0.1047, -0.0016]],\n",
            "\n",
            "        [[ 0.0880, -0.0183,  0.0747],\n",
            "         [ 0.1105,  0.1129, -0.0668],\n",
            "         [ 0.0223, -0.0303, -0.0723]],\n",
            "\n",
            "        [[-0.0413,  0.0702,  0.0208],\n",
            "         [ 0.0309, -0.1006, -0.0525],\n",
            "         [ 0.0119,  0.0153,  0.0332]],\n",
            "\n",
            "        [[-0.0299,  0.0308,  0.0753],\n",
            "         [ 0.0042,  0.0137, -0.1106],\n",
            "         [-0.0114,  0.0606, -0.0162]],\n",
            "\n",
            "        [[-0.0284, -0.0683,  0.0068],\n",
            "         [-0.0261,  0.0373, -0.1044],\n",
            "         [ 0.0474,  0.0090, -0.0414]],\n",
            "\n",
            "        [[ 0.0192,  0.0361,  0.0437],\n",
            "         [ 0.0047,  0.0211,  0.0876],\n",
            "         [-0.0186,  0.0623,  0.0582]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# second filter\n",
        "print(f'Size of second filter: \\n{first_conv_2d.weight.data[1].shape}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XImj_FYtw2ZU",
        "outputId": "26f556c4-7bc8-455a-d45b-005edeb8a6f5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of second filter: \n",
            "torch.Size([8, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the weights of all the convolution filters\n",
        "print(f'Weights: \\n{first_conv_2d.weight.data}')\n",
        "\n",
        "# Print the biases of the all the convolution filters\n",
        "print(f'Biases: \\n{first_conv_2d.bias.data}')"
      ],
      "metadata": {
        "id": "9hvzq3qYwS7K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c1a7ec59-0413-4cbd-c6f1-967f648f7472"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: \n",
            "tensor([[[[ 0.0857, -0.1086, -0.0108],\n",
            "          [ 0.0715,  0.0448, -0.0716],\n",
            "          [ 0.1054,  0.0358,  0.0970]],\n",
            "\n",
            "         [[ 0.0556,  0.0968,  0.0547],\n",
            "          [ 0.1030,  0.0508,  0.0030],\n",
            "          [-0.0906, -0.1054, -0.0420]],\n",
            "\n",
            "         [[-0.0897,  0.0460,  0.0294],\n",
            "          [-0.0624, -0.0090,  0.0548],\n",
            "          [ 0.0541, -0.1047, -0.0016]],\n",
            "\n",
            "         [[ 0.0880, -0.0183,  0.0747],\n",
            "          [ 0.1105,  0.1129, -0.0668],\n",
            "          [ 0.0223, -0.0303, -0.0723]],\n",
            "\n",
            "         [[-0.0413,  0.0702,  0.0208],\n",
            "          [ 0.0309, -0.1006, -0.0525],\n",
            "          [ 0.0119,  0.0153,  0.0332]],\n",
            "\n",
            "         [[-0.0299,  0.0308,  0.0753],\n",
            "          [ 0.0042,  0.0137, -0.1106],\n",
            "          [-0.0114,  0.0606, -0.0162]],\n",
            "\n",
            "         [[-0.0284, -0.0683,  0.0068],\n",
            "          [-0.0261,  0.0373, -0.1044],\n",
            "          [ 0.0474,  0.0090, -0.0414]],\n",
            "\n",
            "         [[ 0.0192,  0.0361,  0.0437],\n",
            "          [ 0.0047,  0.0211,  0.0876],\n",
            "          [-0.0186,  0.0623,  0.0582]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0068,  0.0946, -0.0354],\n",
            "          [ 0.0144,  0.0688, -0.1099],\n",
            "          [-0.1044,  0.0230,  0.1153]],\n",
            "\n",
            "         [[-0.0762, -0.0275,  0.0986],\n",
            "          [-0.0394, -0.0095, -0.0085],\n",
            "          [ 0.0121,  0.0526, -0.0334]],\n",
            "\n",
            "         [[-0.1093, -0.0647, -0.1005],\n",
            "          [ 0.0686, -0.0234, -0.0878],\n",
            "          [ 0.0369,  0.0683,  0.0325]],\n",
            "\n",
            "         [[-0.0480,  0.0686, -0.1101],\n",
            "          [ 0.0037,  0.0932, -0.1081],\n",
            "          [-0.0949, -0.0666, -0.0715]],\n",
            "\n",
            "         [[-0.0910,  0.0746,  0.0151],\n",
            "          [-0.1168, -0.1118, -0.0068],\n",
            "          [-0.0698, -0.1114,  0.1102]],\n",
            "\n",
            "         [[ 0.0834,  0.1046,  0.1147],\n",
            "          [-0.0072,  0.1009,  0.0043],\n",
            "          [ 0.0002, -0.0733, -0.0117]],\n",
            "\n",
            "         [[ 0.0802,  0.0355,  0.1171],\n",
            "          [-0.0426, -0.1080,  0.0199],\n",
            "          [ 0.0135,  0.0770, -0.0745]],\n",
            "\n",
            "         [[-0.0454,  0.0516,  0.0830],\n",
            "          [-0.0298, -0.0741,  0.0971],\n",
            "          [ 0.0461,  0.1115,  0.0993]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0881, -0.0087, -0.1074],\n",
            "          [-0.0858, -0.0470,  0.1036],\n",
            "          [-0.0241, -0.0597,  0.0562]],\n",
            "\n",
            "         [[-0.1034, -0.0508, -0.1068],\n",
            "          [ 0.0104, -0.0332,  0.0652],\n",
            "          [ 0.0120, -0.0967, -0.0800]],\n",
            "\n",
            "         [[ 0.1124,  0.0352, -0.0729],\n",
            "          [-0.0446, -0.1165,  0.0606],\n",
            "          [-0.0606,  0.0310,  0.1155]],\n",
            "\n",
            "         [[ 0.1047,  0.0103,  0.0629],\n",
            "          [-0.0377, -0.0233, -0.0721],\n",
            "          [-0.0166,  0.0743,  0.0109]],\n",
            "\n",
            "         [[ 0.1023,  0.0338, -0.0950],\n",
            "          [ 0.0256,  0.1172,  0.0462],\n",
            "          [-0.0432, -0.1086, -0.0390]],\n",
            "\n",
            "         [[ 0.0749,  0.0753, -0.0103],\n",
            "          [ 0.1001, -0.0004,  0.0451],\n",
            "          [ 0.0897, -0.0706,  0.0993]],\n",
            "\n",
            "         [[ 0.1033, -0.0527, -0.0834],\n",
            "          [ 0.0703, -0.0044, -0.0688],\n",
            "          [-0.0687,  0.1136,  0.0296]],\n",
            "\n",
            "         [[ 0.0106,  0.0810, -0.0150],\n",
            "          [-0.0356,  0.0466, -0.0468],\n",
            "          [ 0.0956, -0.0297,  0.1020]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0656,  0.0461, -0.0965],\n",
            "          [ 0.1015,  0.0717, -0.1150],\n",
            "          [ 0.0026,  0.0762,  0.0254]],\n",
            "\n",
            "         [[-0.0041,  0.0765,  0.1169],\n",
            "          [-0.0163, -0.1067, -0.0780],\n",
            "          [ 0.1124, -0.0693, -0.0513]],\n",
            "\n",
            "         [[-0.0634,  0.1092,  0.0635],\n",
            "          [-0.1111, -0.1046, -0.0252],\n",
            "          [-0.0851,  0.0413,  0.0076]],\n",
            "\n",
            "         [[ 0.0886, -0.0627, -0.1002],\n",
            "          [ 0.0434, -0.0138, -0.1118],\n",
            "          [-0.0040,  0.0721, -0.0408]],\n",
            "\n",
            "         [[-0.1040,  0.0627,  0.0485],\n",
            "          [ 0.0964, -0.1027, -0.0339],\n",
            "          [ 0.0198,  0.1171, -0.0020]],\n",
            "\n",
            "         [[-0.0865,  0.0089, -0.0982],\n",
            "          [ 0.0493,  0.0409,  0.0216],\n",
            "          [-0.0081,  0.0418, -0.1151]],\n",
            "\n",
            "         [[ 0.0921,  0.0809, -0.0293],\n",
            "          [ 0.0072, -0.0734, -0.0327],\n",
            "          [ 0.0955,  0.0750,  0.0792]],\n",
            "\n",
            "         [[ 0.0230, -0.0694, -0.0063],\n",
            "          [ 0.1065,  0.0696, -0.0498],\n",
            "          [ 0.0106, -0.1071, -0.0022]]],\n",
            "\n",
            "\n",
            "        [[[-0.0150,  0.0682,  0.0850],\n",
            "          [-0.0601,  0.0833, -0.0039],\n",
            "          [-0.0248, -0.0439, -0.0316]],\n",
            "\n",
            "         [[ 0.0706, -0.0974,  0.1104],\n",
            "          [-0.0253, -0.0483,  0.0578],\n",
            "          [ 0.1177,  0.0290,  0.0642]],\n",
            "\n",
            "         [[-0.0596, -0.0622,  0.0652],\n",
            "          [-0.0266, -0.0169, -0.0054],\n",
            "          [-0.0148,  0.1126,  0.0136]],\n",
            "\n",
            "         [[ 0.0202,  0.0250,  0.0652],\n",
            "          [ 0.0033, -0.1127,  0.0060],\n",
            "          [ 0.0380,  0.1152, -0.0588]],\n",
            "\n",
            "         [[-0.1111,  0.0860,  0.1099],\n",
            "          [-0.1158, -0.0992, -0.0960],\n",
            "          [ 0.0093,  0.0765, -0.0551]],\n",
            "\n",
            "         [[-0.0615, -0.0695, -0.0004],\n",
            "          [ 0.0622, -0.0540,  0.0593],\n",
            "          [-0.0339,  0.0899, -0.0048]],\n",
            "\n",
            "         [[ 0.0199, -0.0420, -0.0708],\n",
            "          [-0.0459, -0.0399, -0.1065],\n",
            "          [-0.0645, -0.0781,  0.0145]],\n",
            "\n",
            "         [[ 0.0696,  0.0817, -0.0629],\n",
            "          [-0.0461,  0.1060,  0.0035],\n",
            "          [-0.0514,  0.0356, -0.0291]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0282, -0.1027, -0.0976],\n",
            "          [-0.0194, -0.1061, -0.0964],\n",
            "          [ 0.0636, -0.0367, -0.0865]],\n",
            "\n",
            "         [[ 0.0225, -0.0305,  0.1074],\n",
            "          [-0.0325, -0.0748, -0.1038],\n",
            "          [-0.0612, -0.0517,  0.1029]],\n",
            "\n",
            "         [[-0.0915, -0.1145, -0.0824],\n",
            "          [ 0.0236,  0.0619, -0.1152],\n",
            "          [ 0.0813,  0.0504, -0.0814]],\n",
            "\n",
            "         [[-0.0058, -0.0277, -0.0677],\n",
            "          [ 0.0390,  0.1025,  0.0442],\n",
            "          [-0.0351,  0.0217,  0.1091]],\n",
            "\n",
            "         [[ 0.0050,  0.1086,  0.0023],\n",
            "          [ 0.0016, -0.0074,  0.1014],\n",
            "          [ 0.0977,  0.0714, -0.0998]],\n",
            "\n",
            "         [[ 0.0791,  0.0266,  0.0874],\n",
            "          [ 0.0506, -0.1156,  0.0052],\n",
            "          [-0.1037,  0.1065,  0.0809]],\n",
            "\n",
            "         [[ 0.0218,  0.0272,  0.0344],\n",
            "          [-0.0389, -0.0226,  0.1014],\n",
            "          [ 0.0287, -0.0702, -0.0014]],\n",
            "\n",
            "         [[-0.0784, -0.0300, -0.0385],\n",
            "          [-0.0646,  0.0880, -0.0224],\n",
            "          [ 0.0242,  0.0091,  0.0762]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0175, -0.0336, -0.0495],\n",
            "          [ 0.0131, -0.0698, -0.0212],\n",
            "          [-0.1124, -0.0175, -0.0887]],\n",
            "\n",
            "         [[ 0.0760,  0.0551, -0.0911],\n",
            "          [ 0.0794,  0.0196,  0.0563],\n",
            "          [-0.0688,  0.0374,  0.0229]],\n",
            "\n",
            "         [[-0.0363, -0.0955,  0.0530],\n",
            "          [-0.0211, -0.0040,  0.0204],\n",
            "          [ 0.0450, -0.0942, -0.1147]],\n",
            "\n",
            "         [[ 0.0047, -0.1173,  0.0989],\n",
            "          [ 0.0023,  0.0923, -0.0156],\n",
            "          [ 0.0414,  0.0750, -0.0949]],\n",
            "\n",
            "         [[-0.0052,  0.0021, -0.0955],\n",
            "          [ 0.0445, -0.0683, -0.0468],\n",
            "          [ 0.0413, -0.0447, -0.0750]],\n",
            "\n",
            "         [[ 0.0183,  0.0625,  0.0207],\n",
            "          [ 0.0362,  0.0091,  0.0475],\n",
            "          [-0.0466, -0.0090, -0.0165]],\n",
            "\n",
            "         [[ 0.0549,  0.1109, -0.0197],\n",
            "          [ 0.1074, -0.0921, -0.0239],\n",
            "          [-0.1085, -0.0024,  0.0348]],\n",
            "\n",
            "         [[-0.0449, -0.0883,  0.0043],\n",
            "          [ 0.0574, -0.0569, -0.0210],\n",
            "          [-0.1120,  0.0736,  0.1094]]],\n",
            "\n",
            "\n",
            "        [[[-0.0301, -0.0458,  0.0034],\n",
            "          [-0.0516,  0.1114, -0.0090],\n",
            "          [-0.0950, -0.0681, -0.0234]],\n",
            "\n",
            "         [[-0.0349,  0.0817, -0.1033],\n",
            "          [-0.0693, -0.0229, -0.0168],\n",
            "          [ 0.0532, -0.0047, -0.0397]],\n",
            "\n",
            "         [[-0.1118, -0.0248,  0.0373],\n",
            "          [-0.0512,  0.0518, -0.1100],\n",
            "          [ 0.0464, -0.0509,  0.0671]],\n",
            "\n",
            "         [[ 0.0302, -0.0562, -0.0705],\n",
            "          [-0.0374,  0.0821, -0.0912],\n",
            "          [-0.0833,  0.0055, -0.0871]],\n",
            "\n",
            "         [[ 0.1151,  0.0835,  0.0298],\n",
            "          [ 0.0142, -0.0288, -0.0523],\n",
            "          [-0.0481, -0.0786,  0.1033]],\n",
            "\n",
            "         [[-0.0351,  0.0253,  0.0458],\n",
            "          [ 0.0064, -0.1075, -0.0766],\n",
            "          [-0.0776,  0.1177,  0.0149]],\n",
            "\n",
            "         [[ 0.0891, -0.0669,  0.0400],\n",
            "          [ 0.0979, -0.0054,  0.0207],\n",
            "          [-0.0367,  0.0373, -0.0710]],\n",
            "\n",
            "         [[-0.1054, -0.0783,  0.0800],\n",
            "          [-0.0547, -0.1145, -0.0731],\n",
            "          [ 0.0254,  0.0232, -0.0953]]]])\n",
            "Biases: \n",
            "tensor([ 0.1096, -0.1010,  0.0918, -0.0499,  0.0997, -0.0034, -0.0609,  0.1157])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's generate a random input for our convolution layer and plug it into our layer**"
      ],
      "metadata": {
        "id": "9-8gky6gn2rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 1 random sample tensor of shape (B, C, H, W) for the above 2D convolutional network\n",
        "torch.manual_seed(0) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples = 1\n",
        "image_channel     = 8\n",
        "image_height      = 7\n",
        "image_width       = 6\n",
        "\n",
        "random_X              = torch.randn(number_of_samples, image_channel, image_width, image_height)\n",
        "print(f'input shape: \\n{random_X.shape}\\n')\n",
        "#print(f'input numbers: \\n{random_X.numpy()}\\n') # it will produce a large tensor of values\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                = first_conv_2d(random_X)\n",
        "print(f'output shape: \\n{output.data.shape}\\n')\n",
        "#print(f'output layer value: \\n{output.data.numpy()}\\n') # it will produce a large tensor of values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2V0Gyc3oBzz",
        "outputId": "7080d83f-4298-4c0b-b1d5-9c82a162366b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: \n",
            "torch.Size([1, 8, 6, 7])\n",
            "\n",
            "output shape: \n",
            "torch.Size([1, 8, 4, 5])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Group Exercise#1**\n",
        "Create a new 2D convolution layer with the following structure:\n",
        "\n",
        "> its input volume has 3 channels\n",
        "\n",
        "> the output volume will be of 64 channels\n",
        "\n",
        "> each filter has a size of (5x5)\n",
        "\n",
        "> default stride size is 1 (don't need to change that but you are free to explore)\n",
        "\n",
        "> default padding size is 0 (don't need to change that but you are free to explore)\n"
      ],
      "metadata": {
        "id": "a-LTmGiyp566"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "# ...\n",
        "# ..."
      ],
      "metadata": {
        "id": "v_taKRZgqBde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Group Exercise#2**\n",
        "\n",
        "> apply a tensor through your 2D convolution layer now.\n",
        "\n",
        "> change the value in torch.manual_seed(0) to something else, generate new inputs, and pass the tensor through your 2D convolution layer.\n",
        "\n",
        "> observe the the output shapes specially (since the values are hard to inspect so we will leave them for later classes)\n",
        "\n",
        "> convince yourself that the shapes you are observing match your hand calculations."
      ],
      "metadata": {
        "id": "QVPRiA7ZqOfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "# ...\n",
        "# ..."
      ],
      "metadata": {
        "id": "4hsvGpLUqbSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's add an activation function such as *ReLu(), tanh(), or sigmoid()* after your 2D convolution layer and run the experiment again to see how it changes the outputs.**"
      ],
      "metadata": {
        "id": "BOPOELyQsY1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construction of a 2D convolutional layer (useful for feature map learning from the grid layouts of an image)\n",
        "input_volume_channel_first  = 1\n",
        "output_volume_channel_first = 32\n",
        "filter_size                 = 3\n",
        "\n",
        "first_conv_2d               = nn.Conv2d(input_volume_channel_first, output_volume_channel_first, filter_size)  # 2D convolutional transformation module :input_volume_channel=1, output_volume_channel=32, filter_size= (3x3)\n",
        "relu_activation             = nn.ReLU()\n",
        "sigmoid_activation          = nn.Sigmoid()\n",
        "tanh_activation             = nn.Tanh()\n",
        "\n"
      ],
      "metadata": {
        "id": "DRw_QBK4sdTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Using ReLU activation function**"
      ],
      "metadata": {
        "id": "3Ys-fzHCuqAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 1 random sample tensor of shape (B, C, H, W) for the above 2D convolutional network\n",
        "torch.manual_seed(0) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples = 1\n",
        "image_channel     = 1\n",
        "image_height      = 28\n",
        "image_width       = 28\n",
        "\n",
        "random_X              = torch.randn(number_of_samples, image_channel, image_width, image_height)\n",
        "print(f'input shape: \\n{random_X.shape}\\n')\n",
        "#print(f'input numbers: \\n{random_X.numpy()}\\n') # it will produce a large tensor of values\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = first_conv_2d(random_X)\n",
        "print(f'output shape: \\n{output.data.shape}\\n')\n",
        "#print(f'output layer value: \\n{output.data.numpy()}\\n') # it will produce a large tensor of values\n",
        "output_after_activation   = relu_activation(output)\n",
        "print(f'No change in output shape after activation: \\n{output.data.shape}\\n')\n",
        "#print(f'output layer value (each number could have any value): \\n{output.data.numpy()}\\n')\n",
        "#print(f'ReLU activation value (each number must be within [0.0 to infinity] NO NEGATIVE NUMBER): \\n{output_after_activation.data.numpy()}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg-a_ZfpuiWl",
        "outputId": "49ddf233-52a7-4bf7-c17d-5dc3558c5c8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: \n",
            "torch.Size([1, 1, 28, 28])\n",
            "\n",
            "output shape: \n",
            "torch.Size([1, 32, 26, 26])\n",
            "\n",
            "No change in output shape after activation: \n",
            "torch.Size([1, 32, 26, 26])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's build a 2 layer convolutional neural network (CNN)!**\n",
        "\n",
        "First convolution layer has:\n",
        "  > its input volume has 3 channels (inputs are RGB color images)\n",
        "\n",
        "  > the output volume will have 64 channels\n",
        "\n",
        "  > each filter has a size of (3x3)\n",
        "\n",
        "Second convolution layer has:\n",
        "  > its input volume has 64 channels\n",
        "\n",
        "  > the output volume will have 128 channels\n",
        "\n",
        "  > each filter has a size of (3x3)\n"
      ],
      "metadata": {
        "id": "0h5ShXNNliD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construction\n",
        "input_volume_channel_first    = 3\n",
        "output_volume_channel_first   = 32\n",
        "input_volume_channel_second   = 32\n",
        "output_volume_channel_second  = 128\n",
        "filter_size                   = 3\n",
        "\n",
        "first_conv_2d                 = nn.Conv2d(input_volume_channel_first, output_volume_channel_first, filter_size)  # 2D convolutional transformation module :input_volume_channel=1, output_volume_channel=32, filter_size= (3x3)\n",
        "first_relu_activation         = nn.ReLU()\n",
        "second_conv_2d                = nn.Conv2d(input_volume_channel_second, output_volume_channel_second, filter_size)  # 2D convolutional transformation module :input_volume_channel=1, output_volume_channel=32, filter_size= (3x3)\n",
        "second_relu_activation        = nn.ReLU()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sml5o0uepNvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **We can apply a tensor through the CNN layers now**"
      ],
      "metadata": {
        "id": "bN0-x03AlkfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 1 random sample tensor of shape (B, C, H, W) for the above 2D convolutional network\n",
        "torch.manual_seed(0) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples = 1\n",
        "image_channel     = 3\n",
        "image_height      = 28\n",
        "image_width       = 28\n",
        "\n",
        "random_X              = torch.randn(number_of_samples, image_channel, image_width, image_height)\n",
        "print(f'input shape: \\n{random_X.shape}\\n')\n",
        "#print(f'input numbers: \\n{random_X.numpy()}\\n') # it will produce a large tensor of values\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = first_conv_2d(random_X)\n",
        "print(f'First conv2d: output shape: \\n{output.data.shape}\\n')\n",
        "output                    = first_relu_activation(output)\n",
        "print(f'First activation: output shape (no change): \\n{output.data.shape}\\n')\n",
        "\n",
        "output                    = second_conv_2d(output)\n",
        "print(f'Second conv2d: output shape: \\n{output.data.shape}\\n')\n",
        "output                    = second_relu_activation(output)\n",
        "#print(f'output layer value: \\n{output.data.numpy()}\\n') # it will produce a large tensor of values\n",
        "print(f'Second activation: output shape (no change): \\n{output.data.shape}\\n')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12dr7m-Mj1in",
        "outputId": "38bb05c3-6876-4621-eecb-05700526f90e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: \n",
            "torch.Size([1, 3, 28, 28])\n",
            "\n",
            "First conv2d: output shape: \n",
            "torch.Size([1, 32, 26, 26])\n",
            "\n",
            "First activation: output shape (no change): \n",
            "torch.Size([1, 32, 26, 26])\n",
            "\n",
            "Second conv2d: output shape: \n",
            "torch.Size([1, 128, 24, 24])\n",
            "\n",
            "Second activation: output shape (no change): \n",
            "torch.Size([1, 128, 24, 24])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Group Exercise#3**\n",
        "Let's create a CNN with three conv2d layers and connect them in a sequence with the following structure:\n",
        "\n",
        "First convolution layer has:\n",
        "  > its input volume has 3 channels\n",
        "\n",
        "  > the output volume will be of 64 channels\n",
        "\n",
        "  > each filter has a size of (5x5)\n",
        "\n",
        "Second convolution layer has:\n",
        "  > its input volume has 64 channels\n",
        "\n",
        "  > the output volume will be of 128 channels\n",
        "\n",
        "  > each filter has a size of (5x5)\n"
      ],
      "metadata": {
        "id": "Vn_XY5pRj_XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "# ...\n",
        "# ..."
      ],
      "metadata": {
        "id": "nxie_gB-mOqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Group Exercise#4**\n",
        "> Apply a tensor through your CNN layers now."
      ],
      "metadata": {
        "id": "4ShpPaSFmSdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "# ...\n",
        "# ..."
      ],
      "metadata": {
        "id": "ReH2hHydmnQY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}