{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZHCW6hBWXT7SNIRsGh2DX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alimoorreza/CS167-sp25-notes/blob/main/Day27b_LLM_paraphrase_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS167: Day27\n",
        "## Deep Learning and Large Language Models (LLMs)\n",
        "\n",
        "\n",
        "#### CS167: Machine Learning, Spring 2025\n",
        "\n",
        "\n",
        "ðŸ“œ [Syllabus](https://analytics.drake.edu/~reza/teaching/cs167_sp25/cs167_syllabus_sp25.pdf)"
      ],
      "metadata": {
        "id": "6zf1VyBwY1RK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0CmiA-R3Tk7",
        "outputId": "4722c8d1-9fab-4163-b627-074a98ab8cd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Paraphrase Detection Model using Transformer-based large language model (LLM)\n",
        ">**many-to-one** mapping machine learning task:\n",
        "<div>\n",
        "<img src=\"https://analytics.drake.edu/~reza/teaching/cs167_sp25/notes/images/many_to_one_ML_task.png?raw=1\" width=200/>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "oRTe6v-v5l9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
        "model     = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n"
      ],
      "metadata": {
        "id": "9Hc5LKqp36rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels          = [\"not paraphrase (NP)\", \"paraphrase (P)\"]\n",
        "input_sentences = [\"Lions live in African plains\", \"African plains are habitats for lions\", \"Tigers are the strongest among big cats\"]\n",
        "\n",
        "for ii in range(len(input_sentences)-1):\n",
        "  pp_vs_not_pp                      = tokenizer(input_sentences[ii], input_sentences[ii+1], return_tensors=\"pt\")\n",
        "  paraphrase_classification_logits  = model(**pp_vs_not_pp).logits\n",
        "  paraphrase_results                = torch.softmax(paraphrase_classification_logits, dim=1).tolist()[0]\n",
        "  max_id                            = np.argmax(paraphrase_results)\n",
        "  pred_label_with_max_id            = labels[max_id]\n",
        "  print(f'The pair of sentences (\\'{input_sentences[ii]}\\', {input_sentences[ii+1]}) is: {pred_label_with_max_id}')\n",
        "\n"
      ],
      "metadata": {
        "id": "Gvds0x544JKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "916c1527-2c90-4ae9-a1bf-bde1687123e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The pair of sentences ('Lions live in African plains', African plains are habitats for lions) is: paraphrase (P)\n",
            "The pair of sentences ('African plains are habitats for lions', Tigers are the strongest among big cats) is: not paraphrase (NP)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# __Group Activty#2__\n",
        "1. Create at least three pairs of new sentences using the following format:\n",
        "\n",
        "|                 | Sentence 1      | Sentence 2       |\n",
        "|-----------------|-----------------|------------------|\n",
        "| Pair#1          | paraphrase      | paraphrase       |\n",
        "| Pair#2          | paraphrase      | not paraphrase   |\n",
        "| Pair#3          | not paraphrase  | paraphrase       |\n",
        "\n",
        "For example, the first pair could be inserted as Pair#1 in the table below _(\"Lions live in African plains\", \"African plains are habitats for lions\")_.\" Because both sentences are paraphrases of one another.\n",
        "\n",
        "|                 | Sentence 1      | Sentence 2       |\n",
        "|-----------------|-----------------|------------------|\n",
        "| Pair#1          | \"Lions live in African plains\"  | \"African plains are habitats for lions\"   |\n",
        "| Pair#2          | ?  | ?      |\n",
        "| Pair#3          | ?      | ?  |\n",
        "\n",
        "2. Try out the __BERT__ pre-trained model on these 3 pairs of input sentences. The for loop index may need adjustment with a simple trick.\n",
        "3. Report the accuracy of your three new pairs of sentences."
      ],
      "metadata": {
        "id": "MCop9LG60Q2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ..."
      ],
      "metadata": {
        "id": "9tLW9EFH6j-M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}