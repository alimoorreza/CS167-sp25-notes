{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alimoorreza/CS167-sp25-notes/blob/main/Day20_MLP_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHJrUI0I4uVJ"
      },
      "source": [
        "# CS167: Day20\n",
        "\n",
        "## MLP using PyTorch\n",
        "\n",
        "\n",
        "#### CS167: Machine Learning, Spring 2025\n",
        "\n",
        "\n",
        "ðŸ“œ [Syllabus](https://analytics.drake.edu/~reza/teaching/cs167_sp25/cs167_syllabus_sp25.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch library\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "LwgBlHEvJDEJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Linear Layers using PyTorch"
      ],
      "metadata": {
        "id": "8JllItQfeVFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's build a linear layer**"
      ],
      "metadata": {
        "id": "K6snyzopmxi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2)                    # for reproducibility\n",
        "# construction of a linear layer\n",
        "\n",
        "input_layer_1 = nn.Linear(2, 4)"
      ],
      "metadata": {
        "id": "WovTledem6Lw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Inspecting the weights of a linear layer**"
      ],
      "metadata": {
        "id": "LbUkNgH5x0uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the weights of the linear layer\n",
        "print(f'Weights: \\n{input_layer_1.weight.data}')\n",
        "\n",
        "# Print the biases of the linear layer (if they exist)\n",
        "print(f'Biases: \\n{input_layer_1.bias.data}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_8I5F12xzuC",
        "outputId": "f29f0625-44d4-4d1d-8187-f20de181c320"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: \n",
            "tensor([[ 0.1622, -0.1683],\n",
            "        [ 0.1939, -0.0361],\n",
            "        [ 0.3021,  0.1683],\n",
            "        [-0.0813, -0.5717]])\n",
            "Biases: \n",
            "tensor([ 0.1614, -0.6260,  0.0929,  0.0470])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's generate a random input for our linear layer and plug it into our layer**"
      ],
      "metadata": {
        "id": "9-8gky6gn2rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 1 random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "number_of_samples     = 1\n",
        "random_input          = torch.randn(number_of_samples, 2)\n",
        "print(f'input numbers: \\n{random_input.numpy()}\\n')\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                = input_layer_1(random_input)\n",
        "print(f'output layer value: \\n{output.data.numpy()}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2V0Gyc3oBzz",
        "outputId": "fdd16f8c-93cf-4e8e-ba7b-f64420c1aba9",
        "collapsed": true
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers: \n",
            "[[ 0.39229682 -0.22356401]]\n",
            "\n",
            "output layer value: \n",
            "[[ 0.26269433 -0.5418888   0.17379826  0.14291513]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 3 random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "number_of_samples     = 4\n",
        "random_input          = torch.randn(number_of_samples, 2)\n",
        "print(f'input numbers: \\n{random_input.numpy()}\\n')\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                = input_layer_1(random_input)\n",
        "print(f'output layer value: \\n{output.data.numpy()}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB-XAtrPWuOi",
        "outputId": "49ecac0c-28dd-406b-c1d5-84ecdd0b290f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers: \n",
            "[[ 0.39229682 -0.22356401]\n",
            " [-0.31950027 -1.2050371 ]\n",
            " [ 1.0444635  -0.6332277 ]\n",
            " [ 0.57310677  0.54094744]]\n",
            "\n",
            "output layer value: \n",
            "[[ 0.26269433 -0.5418888   0.17379826  0.14291513]\n",
            " [ 0.31239414 -0.64446425 -0.20643637  0.7618419 ]\n",
            " [ 0.4374134  -0.40063176  0.30183256  0.32410505]\n",
            " [ 0.1633755  -0.53444034  0.3571151  -0.30882734]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Group Exercise#1**\n",
        "Create a new Linear layer with the following structure:\n",
        "\n",
        "> The first layer has 2 input nodes and 16 output nodes.\n"
      ],
      "metadata": {
        "id": "a-LTmGiyp566"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "\n"
      ],
      "metadata": {
        "id": "v_taKRZgqBde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Group Exercise#2**\n",
        "\n",
        "> Apply a tensor through your linear layer now.\n",
        "\n",
        "> Change the value in torch.manual_seed(0) to something else, generate new inputs, and pass the tensor through your linear layer again.\n",
        "\n",
        "> Observe the the output values."
      ],
      "metadata": {
        "id": "QVPRiA7ZqOfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_samples     = 1\n",
        "random_input          = torch.randn(number_of_samples, 2)\n",
        "print(f'input numbers: \\n{random_input.numpy()}\\n')\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "# your code here\n",
        "# ...\n",
        "\n",
        "print(output.data)"
      ],
      "metadata": {
        "id": "4hsvGpLUqbSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e985af-d5d6-4c4e-e413-9beac69c5c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers: \n",
            "[[0.66689056 0.42576158]]\n",
            "\n",
            "tensor([[ 0.0119, -0.2586,  0.1606,  0.4995, -0.2540, -1.1442,  0.4086, -0.0872,\n",
            "          0.0094,  0.3198,  0.7158, -0.4349, -0.0102,  0.1270,  0.3226, -0.3031]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's add an activation function such as *ReLu(), tanh(), or sigmoid()* after your linear layer and run the experiment again to see how it changes the outputs.**"
      ],
      "metadata": {
        "id": "BOPOELyQsY1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construction of a linear layer\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "input_linear_layer              = nn.Linear(2, 4)  # linear transformation module (input=2, output=4)\n",
        "sigmoid_activation              = nn.Sigmoid()\n",
        "tanh_activation                 = nn.Tanh()\n",
        "relu_activation                 = nn.ReLU()\n",
        "\n"
      ],
      "metadata": {
        "id": "DRw_QBK4sdTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Using Sigmoid activation function**"
      ],
      "metadata": {
        "id": "F0oBQ5evtzsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate some random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples     = 1\n",
        "random_X              = torch.randn(number_of_samples, 2)             # you could imagine that these are pairs of (x1, x2) as shown in the above table\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = input_linear_layer(random_X)\n",
        "output_after_activation   = sigmoid_activation(output)\n",
        "print('output layer value: ')\n",
        "print(output.data.numpy())\n",
        "print('Sigmoid activation value: ')\n",
        "print(output_after_activation.data.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW53vin-tVaH",
        "outputId": "f30caac9-e7d6-4dec-9b29-40679ab62102",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[ 0.39229682 -0.22356401]]\n",
            "output layer value: \n",
            "[[ 0.26766852  0.54952395  0.11569834 -0.22820818  0.5140537  -0.24548726\n",
            "  -0.34690085 -0.43468243 -0.01138236 -0.91387737  0.04074919  0.14083466\n",
            "   0.07245701  0.42237854  0.21927154 -0.11810946]]\n",
            "Sigmoid activation value: \n",
            "[[0.56652045 0.63402516 0.52889234 0.4431943  0.62575626 0.43893453\n",
            "  0.41413417 0.39300877 0.49715444 0.28620705 0.5101859  0.5351506\n",
            "  0.51810634 0.60405225 0.5545993  0.47050694]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Using Tanh activation function**"
      ],
      "metadata": {
        "id": "FJOLsCHuuOcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate some random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples           = 1\n",
        "num_of_neurons_input_layer  = 2\n",
        "random_X                    = torch.randn(number_of_samples, num_of_neurons_input_layer)             # you could imagine that these are pairs of (x1, x2) as shown in the above table\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = input_linear_layer(random_X)\n",
        "output_after_activation   = tanh_activation(output)\n",
        "print('output layer value: ')\n",
        "print(output.data.numpy())\n",
        "print('Tanh() activation value: ')\n",
        "print(output_after_activation.data.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imhy2qSIt6Jw",
        "outputId": "272adac6-8df3-44da-81b7-6bed62e6c76e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[ 0.39229682 -0.22356401]]\n",
            "output layer value: \n",
            "[[ 0.26766852  0.54952395  0.11569834 -0.22820818  0.5140537  -0.24548726\n",
            "  -0.34690085 -0.43468243 -0.01138236 -0.91387737  0.04074919  0.14083466\n",
            "   0.07245701  0.42237854  0.21927154 -0.11810946]]\n",
            "Tanh() activation value: \n",
            "[[ 0.26145405  0.5001633   0.11518484 -0.22432739  0.47309762 -0.24067195\n",
            "  -0.3336242  -0.40922704 -0.01138186 -0.72298807  0.04072665  0.13991086\n",
            "   0.07233047  0.39893234  0.21582365 -0.1175633 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Using ReLU activation function**"
      ],
      "metadata": {
        "id": "3Ys-fzHCuqAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate some random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples           = 1\n",
        "num_of_neurons_input_layer  = 2\n",
        "random_X                    = torch.randn(number_of_samples, num_of_neurons_input_layer)             # you could imagine that these are pairs of (x1, x2) as shown in the above table\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = input_linear_layer(random_X)\n",
        "output_after_activation   = relu_activation(output)\n",
        "print('output layer value: ')\n",
        "print(output.data.numpy())\n",
        "print('ReLU() activation value: ')\n",
        "print(output_after_activation.data.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg-a_ZfpuiWl",
        "outputId": "956ec9b8-effa-4662-96d2-bf20f703323b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[ 0.39229682 -0.22356401]]\n",
            "output layer value: \n",
            "[[ 0.26766852  0.54952395  0.11569834 -0.22820818  0.5140537  -0.24548726\n",
            "  -0.34690085 -0.43468243 -0.01138236 -0.91387737  0.04074919  0.14083466\n",
            "   0.07245701  0.42237854  0.21927154 -0.11810946]]\n",
            "ReLU() activation value: \n",
            "[[0.26766852 0.54952395 0.11569834 0.         0.5140537  0.\n",
            "  0.         0.         0.         0.         0.04074919 0.14083466\n",
            "  0.07245701 0.42237854 0.21927154 0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Group Exercise#3**\n",
        "\n",
        "> Experiment with different activation functions like sigmoid, tanh, and relu, and then pass a tensor through the linear layer you created for Group Exercises #1 and #2.\n",
        "\n",
        "> Change the value in torch.manual_seed(2) to something else, generate new inputs, and pass the tensor through your linear layer again.\n",
        "\n",
        "> Take a look at the output values and make sure they match what you were expecting!"
      ],
      "metadata": {
        "id": "OuOPEOQVu7XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here.\n",
        "# ...\n",
        "\n",
        "# your code here\n",
        "# ...\n",
        "\n"
      ],
      "metadata": {
        "id": "87sDNOLDv3yC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7a3915-f365-4c40-c51c-43fa72961339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "raw output without tanh activation:  tensor([[-1.2720, -0.6114,  0.8026,  0.4835, -1.7741,  0.7322, -0.4001, -1.1050,\n",
            "          0.6595, -0.3363, -0.7856, -0.3908, -1.0170,  0.1928,  1.0073,  0.7339]])\n",
            "raw output with tanh activation:  tensor([[-0.8543, -0.5451,  0.6655,  0.4491, -0.9441,  0.6244, -0.3800, -0.8023,\n",
            "          0.5780, -0.3242, -0.6559, -0.3720, -0.7686,  0.1905,  0.7646,  0.6254]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's build the simple 1-hidden layer feedforward neural network from the lecture slides!**\n",
        "\n",
        "<div>\n",
        "<img src=\"https://analytics.drake.edu/~reza/teaching/cs167_sp25/notes/images/mlp_toy_examle_wo_weights.png\" width=400/>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "0h5ShXNNliD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creation of our network\n",
        "my_first_mlp = nn.Sequential(\n",
        "                nn.Linear(2, 3),\n",
        "                nn.Sigmoid(),\n",
        "                nn.Linear(3, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "RiMWNdZWpZOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# forward pass step\n",
        "rand_input            = torch.randn(1, 2)\n",
        "output                = my_first_mlp(rand_input)\n",
        "print('final output: ', output.data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nngdAVljp0oV",
        "outputId": "11d36539-b31f-4d66-f32c-a750c1b25090"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final output:  tensor([[0.2290]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make the simple 1-Hidden layer feedforwrd neural network from the lecture slides\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "# construction\n",
        "num_of_neurons_input_layer      = 2\n",
        "num_of_neurons_1st_hidden_layer = 3\n",
        "num_of_neurons_output_layer     = 1\n",
        "\n",
        "'''\n",
        "# Alternatively, you could hardcode the values for the number of neurons directly, without using any variables such as 'num_of_neurons_input_layer ' or 'num_of_neurons_1st_hidden_layer'\n",
        "input_linear_layer              = nn.Linear(2, 3)\n",
        "output_linear_layer             = nn.Linear(3, 1) # linear transformation module (input=3, output=1)\n",
        "'''\n",
        "\n",
        "\n",
        "input_linear_layer              = nn.Linear(num_of_neurons_input_layer, num_of_neurons_1st_hidden_layer)  # linear transformation module (input=2, output=3)\n",
        "relu_activation_h1              = nn.ReLU()\n",
        "output_linear_layer             = nn.Linear(num_of_neurons_1st_hidden_layer, num_of_neurons_output_layer) # linear transformation module (input=3, output=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "sml5o0uepNvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **We can apply a tensor through the Linear layers now**"
      ],
      "metadata": {
        "id": "bN0-x03AlkfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's generate 2 random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2)                                    # for reproducibility (you will get the same random number every time you run this cell)\n",
        "number_of_samples               = 1\n",
        "random_X = torch.randn(number_of_samples, 2)             # you could imagine that these are pairs of (x1, x2) as shown in the above table\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())\n",
        "\n",
        "\n",
        "# apply forward pass through the network\n",
        "output = input_linear_layer(random_X)\n",
        "output = relu_activation(output)\n",
        "print('1st-hidden layer feature map shape: ', output.shape)\n",
        "output = output_linear_layer(output)\n",
        "print('Output layer feature map shape: ', output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12dr7m-Mj1in",
        "outputId": "ce989240-172a-4a9d-ee60-d2ae608afe93",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[ 0.39229682 -0.22356401]]\n",
            "1st-hidden layer feature map shape:  torch.Size([1, 3])\n",
            "Output layer feature map shape:  torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **nn.Sequential()__ module:**\n",
        "You can use PyTorch's nn.Sequential module to build a network composed of multiple linear layers arranged sequentially."
      ],
      "metadata": {
        "id": "K260OHszjBAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_simple_network = nn.Sequential(\n",
        "\n",
        "    nn.Linear(2, 4),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(4, 8),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Linear(8, 1)\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "WADDuQcPjL89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's generate 2 random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2)                                    # for reproducibility (you will get the same random number every time you run this cell)\n",
        "number_of_samples               = 1\n",
        "random_X = torch.randn(number_of_samples, 2)             # you could imagine that these are pairs of (x1, x2) as shown in the above table\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())\n",
        "\n",
        "\n",
        "# apply forward pass through the network\n",
        "output = my_simple_network(random_X)\n",
        "print('Output: ', output.data)\n",
        "print('Output layer feature map shape: ', output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJX25JgJjbNJ",
        "outputId": "73f245e7-c928-431b-c39d-217ea722b1cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[ 0.39229682 -0.22356401]]\n",
            "Output:  tensor([[-0.3476]])\n",
            "Output layer feature map shape:  torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Group Exercise#4**\n",
        "Let's create three Linear layers and connect them in sequence to build an MLP with the following structure:\n",
        "\n",
        "> The first layer has 2 input nodes and 3 output nodes.\n",
        "\n",
        "> The second layer takes 3 input nodes and outputs 6 nodes.\n",
        "\n",
        "> The final layer connects 6 input nodes to 2 output nodes."
      ],
      "metadata": {
        "id": "Vn_XY5pRj_XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n",
        "\n"
      ],
      "metadata": {
        "id": "nxie_gB-mOqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Group Exercise#5**\n",
        "> Apply a tensor through your MLP now."
      ],
      "metadata": {
        "id": "4ShpPaSFmSdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n"
      ],
      "metadata": {
        "id": "d_RH5h0-j-wZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b074477-a146-4ea1-871a-787a9ee04985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: [[-0.10926431  2.050371  ]]\n",
            "tensor([[ 0.9956,  0.6787, -0.6046,  0.2731, -0.8401,  1.8332]])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}